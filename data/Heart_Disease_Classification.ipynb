{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heart Disease Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adam\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KFold\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import product\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'heart_cleveland_upload.csv'\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show basic info\n",
    "print(df.info())  # Check for missing values and data types\n",
    "print(df.describe())  # Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking if dataframe has missing values\n",
    "if pd.isna(df).values.any()>0:\n",
    "    print(\"The Data has missing values\")\n",
    "else:\n",
    "    print(\"The Data has no missing values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = 4, 4\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, column in enumerate(df.columns):\n",
    "    sns.histplot(df[column], kde=True, bins=30, ax=axes[i])\n",
    "    axes[i].set_title(f'Distribution of {column}')\n",
    "    axes[i].set_xlabel(column)\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "    \n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As a next step the categorical data is going to be hot one encoded\n",
    "df = pd.get_dummies(df, drop_first=True)  # One-hot encoding\n",
    "\n",
    "#One hot enconding is not working because we're working with numerical variables and not categories, so instead we will map the conditions\n",
    "#corresponding to each number in each categorical variable\n",
    "\n",
    "mapcp = {0:\"typical Angina\", 1:\"atypical angina\",2:\"non-anginal pain\", 3:\"asymptomatic\"} \n",
    "df[\"cp_coded\"] = df[\"cp\"].map(mapcp)\n",
    "df = df.drop(\"cp\", axis=1)\n",
    "\n",
    "maprestcg = {0:\"normal\",1:\"ST-T\",2:\"hypertrophy\"}\n",
    "df[\"restecg_coded\"] = df[\"restecg\"].map(maprestcg)\n",
    "df = df.drop(\"restecg\", axis=1)\n",
    "\n",
    "mapslope = {0:\"upsloping\",1:\"flat\",2:\"downsloping\"}\n",
    "df[\"slope_coded\"] = df[\"slope\"].map(mapslope)\n",
    "df = df.drop(\"slope\",axis=1)\n",
    "\n",
    "mapthal = {0:\"normal\",1:\"fixed\",2:\"reversable\"}\n",
    "df[\"thal_coded\"] = df[\"thal\"].map(mapthal)\n",
    "df = df.drop(\"thal\",axis=1)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now that we have our categories in place we can proceed with one-hot encoding\n",
    "df = pd.get_dummies(df, drop_first=True)  # One-hot encoding\n",
    "df = df.astype(int)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking if the target is balanced\n",
    "c0=0\n",
    "c1=0\n",
    "for value in df[\"condition\"]:\n",
    "    if value==1:\n",
    "        c1+=1\n",
    "    else:\n",
    "        c0+=1\n",
    "print(f\"{c1} pacients have a condition, {c0} have not\")\n",
    "print(f\"Ratio: {c1/(c1+c0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As it looks since there is no high disparity between healthy people and pacients\n",
    "#Next in line is Normalization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into Train and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate data from labels\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "print(X.head())\n",
    "print()\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test set: 80:20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training Set:       X_train={X_train.shape},    y_train={y_train.shape}\")\n",
    "print(f\"Test Set:           X_test={X_test.shape},      y_test={y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ('Logistic Regression', 'SVM', 'Random forest', 'KNN', 'XGBoost', 'Neural Network')\n",
    "best_models = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search to find the best parameter C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(solver='liblinear', max_iter=300)\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=log_reg,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,                # 5-fold cross-validation\n",
    "    scoring='accuracy',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_log_reg = grid_search.best_estimator_\n",
    "best_models.append(best_log_reg)\n",
    "print(\"Best C from GridSearchCV:\", grid_search.best_params_['C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics (Classification Report, Confusion Matrix and ROC Curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(best_log_reg, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search to find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svc = SVC(probability=True)\n",
    "\n",
    "# param_grid = {\n",
    "#     'C': [0.01, 0.1, 1, 10, 100],\n",
    "#     'kernel': ['linear', 'rbf'],\n",
    "#     'gamma': ['scale', 'auto']      # for rbf\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(\n",
    "#     estimator=svc,\n",
    "#     param_grid=param_grid,\n",
    "#     cv=5,\n",
    "#     scoring='accuracy',\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# best_svm = grid_search.best_estimator_\n",
    "# best_models.append(best_svm)\n",
    "# print(\"Best Parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_svm = SVC(C=10, kernel='linear', probability=True)\n",
    "best_svm.fit(X_train, y_train)\n",
    "best_models.append(best_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics (Classification Report, Confusion Matrix and ROC Curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(best_svm, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search to find the best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics (Classification Report, Confusion Matrix and ROC Curve)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search to find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11, 15, 25, 30],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=knn,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_knn = grid_search.best_estimator_\n",
    "best_models.append(best_knn)\n",
    "print(\"Best Parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_knn = KNeighborsClassifier(n_neighbors=11, weights='distance', metric='manhattan')\n",
    "# best_models.append(best_knn)\n",
    "# print(\"Best Parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics (Classification Report, Confusion Matrix and ROC Curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(best_knn, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search to find the best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics (Classification Report, Confusion Matrix and ROC Curve)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(lr=0.001):\n",
    "    model = Sequential([\n",
    "        Input(shape=(X_train.shape[1],)),\n",
    "        Dense(12, activation='relu'),\n",
    "        Dense(8, activation='relu'),\n",
    "        Dense(4, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=Adam(learning_rate=lr),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search to find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_values = [0.0001, 0.001, 0.01, 0.1]\n",
    "# batch_sizes = [8, 16, 32, 64]\n",
    "# epochs_list = [50, 100, 150, 200] \n",
    "\n",
    "# # Prepare the KFold cross-validation\n",
    "# X_train = np.array(X_train)\n",
    "# y_train = np.array(y_train)\n",
    "\n",
    "# kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# best_accuracy = 0\n",
    "# best_params = {}\n",
    "\n",
    "# for lr, batch_size, epochs in product(lr_values, batch_sizes, epochs_list):\n",
    "#     fold_accuracies = []\n",
    "    \n",
    "#     for train_index, val_index in kf.split(X_train):\n",
    "#         X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "#         y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "        \n",
    "#         model = build_model(lr=lr)\n",
    "#         model.fit(X_train_fold, y_train_fold, batch_size=batch_size, epochs=epochs, verbose=0)\n",
    "        \n",
    "#         y_pred_fold = (model.predict(X_val_fold) > 0.5).astype(int)\n",
    "        \n",
    "#         accuracy = accuracy_score(y_val_fold, y_pred_fold)\n",
    "#         fold_accuracies.append(accuracy)\n",
    "    \n",
    "#     mean_accuracy = np.mean(fold_accuracies)\n",
    "    \n",
    "#     if mean_accuracy > best_accuracy:\n",
    "#         best_accuracy = mean_accuracy\n",
    "#         best_params = {'lr': lr, 'batch_size': batch_size, 'epochs': epochs}\n",
    "\n",
    "# print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics (Classification Report, Confusion Matrix and ROC Curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_nn = build_model(lr=best_params['lr'])\n",
    "# best_nn.fit(X_train, y_train, batch_size=best_params['batch_size'], epochs=best_params['epochs'], verbose=0)\n",
    "# best_models.append(best_nn)\n",
    "\n",
    "# print_metrics(best_nn, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_nn = build_model(lr=0.001)\n",
    "best_nn.fit(X_train, y_train, batch_size=16, epochs=100, verbose=0)\n",
    "best_models.append(best_nn)\n",
    "\n",
    "print_metrics(best_nn, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
